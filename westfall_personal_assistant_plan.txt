# Westfall Personal Assistant Plan

## 1. Core Requirements

### 1.1 Three-Tier Thinking System
- **Normal Mode**: Standard assistant responses without showing reasoning
- **Thinking Mode**: Exposes reasoning process, shows steps of analysis
- **Research Grade**: Deep analysis with multiple perspectives, thorough examination of problems, citations where relevant

### 1.2 Local Model Management
- File explorer integration to select models from local machine
- Button UI to trigger Windows file explorer dialog
- Support for multiple model formats (GGUF, GGML, Pytorch, etc.)
- Configuration storage for previously used models
- Server lifecycle management:
  - Start server when model is selected
  - Kill previous server process when switching models
  - Graceful shutdown on application close

### 1.3 Screen Capture & Analysis (CRITICAL)
- Continuous or on-demand screenshot capability
- Privacy guarantees:
  - All processing done locally
  - No data transmitted externally
  - Optional masking of sensitive information
- Use cases:
  - Error message detection and analysis
  - Program crash diagnosis
  - UI state recognition
  - Workflow understanding
- Image processing to extract:
  - Text (OCR)
  - UI elements and state
  - Error codes and messages

### 1.4 GPU Acceleration
- Automatic detection of available GPU resources (specifically optimized for RTX 2060)
- Smart layer offloading:
  - Analyze model architecture at load time
  - Calculate safe number of layers to offload based on available VRAM
  - Default safe configuration for RTX 2060 (approx. 6GB VRAM)
  - Dynamic adjustment based on system load
- Memory management to prevent CUDA out-of-memory errors
- User-configurable GPU utilization limits
- Fallback to CPU if GPU issues detected

## 2. Technical Architecture

### 2.1 Frontend
- Electron-based desktop application
  - Cross-platform capability
  - Modern UI with React components
  - Native file system access
  - System tray integration for background operation
- Simple chat interface
- Model selection controls
- Thinking mode toggle (Normal/Thinking/Research)
- Screen capture controls
- Conversation history

### 2.2 Backend Server
- Local model runner
- Process management for server lifecycle
- Context management for conversations
- Memory management to optimize performance
- GPU acceleration manager

### 2.3 Core Modules
- Screen Capture Engine
  - Windows API integration for screenshots
  - Image processing and OCR
  - Error pattern recognition
- Local Model Handler
  - Model loading and unloading
  - Format detection and compatibility
  - Resource allocation
  - GPU offloading optimization
- Internet Search Capability
  - API integration or headless browser
  - Result parsing and context integration
- File System Navigator
  - Read-only access to specified directories
  - Content indexing for reference

## 3. Implementation Plan

### 3.1 Phase 1: Core Infrastructure
- Electron app setup with basic UI
- Model selection and server management
- Simple conversation capabilities
- Initial GPU detection and offloading

### 3.2 Phase 2: Screen Analysis
- Screenshot integration
- Basic OCR and text extraction
- Error message detection

### 3.3 Phase 3: Advanced Features
- Three thinking modes implementation
- Advanced screen analysis
- Internet search integration
- File system navigation
- Optimized GPU acceleration

## 4. Privacy & Security

### 4.1 Data Handling
- All data processed locally
- No cloud dependencies
- Optional local logging with rotation
- Screenshot data temporary storage and secure deletion

### 4.2 Permissions
- Explicit permission requests for screen capture
- Clear boundaries for file system access
- Internet access permissions

## 5. Technical Stack

### 5.1 Frontend
- Electron for desktop app
  - Node.js backend
  - React for UI components
  - Electron IPC for frontend-backend communication

### 5.2 Backend
- Python for model serving and processing
- LangChain or similar for context management
- Tesseract for OCR integration
- PyTorch/CUDA for GPU acceleration

### 5.3 Model Handling
- llama.cpp for efficient inference
- Support for locally downloaded models
- Memory mapping for larger models
- CUDA integration for GPU acceleration
- RTX 2060-specific optimizations

## 6. Testing & Validation
- Basic validation testing for model loading
- Screen capture accuracy tests
- Thinking mode comparison tests
- Performance benchmarking for various models
- GPU memory usage monitoring
- Stress testing with different offloading configurations

## 7. Daily Assistant Features

### 7.1 Persistence & Accessibility
- Auto-start option with Windows
- System tray presence for quick access
- Session persistence across restarts
- Conversation history with searchable archive

### 7.2 User Experience
- Keyboard shortcuts for common actions
- Customizable UI (dark/light themes)
- Adjustable response length preferences
- Notification system for long-running tasks

### 7.3 Context Management
- Conversation memory management
- Multiple conversation threads/topics
- Local knowledge base (personal documents indexing)
- Context window optimization

### 7.4 System Integration
- Basic resource monitoring (prevent overload)
- Optional clipboard integration (analyze copied text)
- Scheduled maintenance (cache clearing, log rotation)

## 8. Application Icon

### 8.1 Icon Requirements
- Vector-based scalable format (.svg preferred)
- Multiple resolution exports for Windows requirements:
  - 16x16 (taskbar, small)
  - 32x32 (taskbar, standard)
  - 48x48 (display in file explorer)
  - 256x256 (high-resolution displays)
- ICO format for Windows application
- Transparency support
- Visible in both light and dark themes

### 8.2 Implementation
- Include icon in Electron build configuration
- Set proper app icon in window creation
- Register icon for taskbar display
- Implement proper scaling in application manifest